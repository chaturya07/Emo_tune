# Emo_tune
AI-powered app that detects facial emotions and recommends Spotify songs accordingly
# EmoTune 

An AI-powered music recommendation app that detects facial emotions using Computer Vision (CNN) and recommends Spotify tracks to match the mood.

---

##  Tech Stack
- **Frontend**: React.js (for webcam preview & UI)
- **Backend**: Python (FastAPI / Flask)
- **Machine Learning**: TensorFlow/Keras, OpenCV
- **API Integration**: Spotify Developer API
- **Tools**: Git, VS Code, Python venv, Node.js

---

##  Milestones (Planned)

### Milestone 1 (Week 1–2): Foundations & Baseline
- Setup GitHub repo & environments (Python + Node).
- Prepare facial emotion dataset (resize, grayscale, normalize).
- Define baseline CNN model (not trained yet).
- Frontend skeleton with webcam preview + placeholders.
- Spotify developer app setup with API keys.

### Milestone 2 (Week 3–4): Model Training
- Train CNN on emotion dataset.
- Evaluate performance (accuracy, F1, confusion matrix).
- Save baseline model.

### Milestone 3 (Week 5–6): Integration
- Connect backend (emotion prediction API) to frontend.
- Integrate Spotify API for song recommendations.
- Display emotion + recommended track in UI.

### Milestone 4 (Week 7–8): Finalization
- Improve model accuracy with augmentation.
- Add user login & personalization.
- Final testing, documentation, and deployment.
## Setup Environment Variables
1. Copy `.env.example` → `.env`
2. Fill in your real secret values
3. Never commit `.env` (it's ignored by git)


---
- **Chaturya Keerthi** (B.Tech IT, Shri Vishnu Engineering College for Women)

---

